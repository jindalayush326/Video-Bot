{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "from io import BytesIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = mp.VideoFileClip(\"a.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract from audio to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = video.audio\n",
    "audio_chunks = audio.iter_chunks(fps=16000, chunksize=100000)\n",
    "\n",
    "# Stack the chunks into a full audio array\n",
    "audio_array = np.vstack(list(audio_chunks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Audio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\speech_recognition\\__init__.py:241\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# attempt to read the file as WAV\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m \u001b[43mwave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_or_fileobject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlittle_endian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[39;00m\n",
      "File \u001b[1;32md:\\software new\\anaconda\\lib\\wave.py:509\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWave_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32md:\\software new\\anaconda\\lib\\wave.py:163\u001b[0m, in \u001b[0;36mWave_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitfp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32md:\\software new\\anaconda\\lib\\wave.py:130\u001b[0m, in \u001b[0;36mWave_read.initfp\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mgetname() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIFF\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile does not start with RIFF id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWAVE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mError\u001b[0m: file does not start with RIFF id",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\speech_recognition\\__init__.py:246\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# attempt to read the file as AIFF\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m \u001b[43maifc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_or_fileobject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlittle_endian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# AIFF is a big-endian format\u001b[39;00m\n",
      "File \u001b[1;32md:\\software new\\anaconda\\lib\\aifc.py:917\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAifc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32md:\\software new\\anaconda\\lib\\aifc.py:358\u001b[0m, in \u001b[0;36mAifc_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# assume it is an open file object already\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitfp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software new\\anaconda\\lib\\aifc.py:316\u001b[0m, in \u001b[0;36mAifc_read.initfp\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mgetname() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFORM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile does not start with FORM id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    317\u001b[0m formdata \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mError\u001b[0m: file does not start with FORM id",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\speech_recognition\\__init__.py:272\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m \u001b[43maifc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43maiff_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (aifc\u001b[38;5;241m.\u001b[39mError, \u001b[38;5;167;01mEOFError\u001b[39;00m):\n",
      "File \u001b[1;32md:\\software new\\anaconda\\lib\\aifc.py:917\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAifc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32md:\\software new\\anaconda\\lib\\aifc.py:358\u001b[0m, in \u001b[0;36mAifc_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# assume it is an open file object already\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitfp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software new\\anaconda\\lib\\aifc.py:314\u001b[0m, in \u001b[0;36mAifc_read.initfp\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m file\n\u001b[1;32m--> 314\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[43mChunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mgetname() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFORM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32md:\\software new\\anaconda\\lib\\chunk.py:63\u001b[0m, in \u001b[0;36mChunk.__init__\u001b[1;34m(self, file, align, bigendian, inclheader)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunkname) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mEOFError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mAudioFile(BytesIO(audio_array\u001b[38;5;241m.\u001b[39mtobytes())) \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Record the audio in chunks from the memory stream\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrecord(source)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Convert speech to text using Google API\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\speech_recognition\\__init__.py:274\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(aiff_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (aifc\u001b[38;5;241m.\u001b[39mError, \u001b[38;5;167;01mEOFError\u001b[39;00m):\n\u001b[1;32m--> 274\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlittle_endian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# AIFF is a big-endian format\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader\u001b[38;5;241m.\u001b[39mgetnchannels() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio must be mono or stereo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Audio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format"
     ]
    }
   ],
   "source": [
    "with sr.AudioFile(BytesIO(audio_array.tobytes())) as source:\n",
    "    # Record the audio in chunks from the memory stream\n",
    "    audio_data = r.record(source)\n",
    "\n",
    "    # Convert speech to text using Google API\n",
    "    text = r.recognize_google(audio_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The resultant text from video is: \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Print the transcription\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThe resultant text from video is: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtext\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the transcription\n",
    "print(\"\\nThe resultant text from video is: \\n\")\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sr.AudioFile(\"a.wav\") as source:\n",
    "    data = r.record(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r.recognize_google(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The resultant text from video is: \n",
      "\n",
      "good morning everyone my name is Ayush Jindal and currently I am in fourth year\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThe resultant text from video is: \\n\") \n",
    "print(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text saved to transcribed_text.pdf\n"
     ]
    }
   ],
   "source": [
    "save_text_to_pdf(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"a.txt\", \"w\") as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: \n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import wave\n",
    "\n",
    "# Function to convert numpy array of audio to a byte stream in WAV format\n",
    "def numpy_to_wav(audio_array, fps=16000):\n",
    "    # Normalize the array and convert it to int16 for WAV format\n",
    "    audio_array = (audio_array * 32767).astype(np.int16)\n",
    "\n",
    "    # Prepare an in-memory buffer to store the audio\n",
    "    wav_buffer = BytesIO()\n",
    "\n",
    "    # Write WAV header and audio content to the buffer\n",
    "    with wave.open(wav_buffer, \"wb\") as wav_file:\n",
    "        wav_file.setnchannels(1)  # Mono audio\n",
    "        wav_file.setsampwidth(2)  # Each sample is 2 bytes (int16)\n",
    "        wav_file.setframerate(fps)\n",
    "        wav_file.writeframes(audio_array.tobytes())\n",
    "\n",
    "    # Move back to the start of the buffer\n",
    "    wav_buffer.seek(0)\n",
    "\n",
    "    return wav_buffer\n",
    "\n",
    "# Function to transcribe video to text using speech recognition\n",
    "def transcribe_video_to_text(video_path):\n",
    "    try:\n",
    "        # Load the video file\n",
    "        video = mp.VideoFileClip(video_path)\n",
    "\n",
    "        # Check if the video has an audio track\n",
    "        if video.audio is None:\n",
    "            print(\"The video does not contain an audio track.\")\n",
    "            return\n",
    "\n",
    "        # Extract audio chunks and process them\n",
    "        audio = video.audio\n",
    "        audio_chunks = []\n",
    "\n",
    "        # Iterate over audio chunks\n",
    "        for chunk in audio.iter_chunks(fps=16000, chunksize=100000):\n",
    "            audio_chunks.append(chunk)\n",
    "\n",
    "        # Stack the chunks into a complete audio array\n",
    "        if len(audio_chunks) > 0:\n",
    "            audio_array = np.vstack(audio_chunks)\n",
    "\n",
    "            # Convert the audio array to mono channel (if necessary)\n",
    "            if audio_array.ndim > 1:\n",
    "                audio_array = np.mean(audio_array, axis=1)  # Convert stereo to mono\n",
    "\n",
    "            # Convert the numpy array to a WAV byte stream\n",
    "            wav_audio = numpy_to_wav(audio_array, fps=16000)\n",
    "\n",
    "            # Initialize the recognizer\n",
    "            r = sr.Recognizer()\n",
    "\n",
    "            # Use the WAV byte stream directly for transcription\n",
    "            with sr.AudioFile(wav_audio) as source:\n",
    "                audio_data = r.record(source)  # Record the entire audio from the source\n",
    "                text = r.recognize_google(audio_data)  # Use Google Speech-to-Text\n",
    "\n",
    "            # Output the transcribed text\n",
    "            print(\"\\nThe resultant text from the video is:\\n\")\n",
    "            print(text)\n",
    "\n",
    "            # Optionally, save the transcription to a text file or PDF\n",
    "            with open(\"c.txt\", \"w\") as file:\n",
    "                file.write(text)\n",
    "            print(\"\\nText saved to transcribed_text.txt\")\n",
    "\n",
    "        else:\n",
    "            print(\"No audio data extracted.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "video_path = \"sample.mp4\"  # Replace with your video file path\n",
    "transcribe_video_to_text(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Transcribing from 0.00 to 4.00 seconds...\n",
      "\n",
      "The resultant text from the video is:\n",
      "\n",
      "hello my name is Ayush singer\n",
      "\n",
      "Text saved to transcribed_text.txt\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to transcribe video to text\n",
    "def transcribe_video_to_text(video_path, chunk_size=30):\n",
    "    try:\n",
    "        # Load the video file\n",
    "        video = mp.VideoFileClip(video_path)\n",
    "\n",
    "        # Check if the video has an audio track\n",
    "        if video.audio is None:\n",
    "            print(\"The video does not contain an audio track.\")\n",
    "            return\n",
    "\n",
    "        # Extract audio and convert it to pydub AudioSegment\n",
    "        audio_path = \"temp_audio.wav\"\n",
    "        video.audio.write_audiofile(audio_path, codec='pcm_s16le')  # Save audio to temp file\n",
    "        audio_segment = AudioSegment.from_wav(audio_path)\n",
    "\n",
    "        # Initialize recognizer\n",
    "        recognizer = sr.Recognizer()\n",
    "        total_duration = len(audio_segment) / 1000.0  # Duration in seconds\n",
    "        transcribed_text = []\n",
    "\n",
    "        # Process the audio in chunks\n",
    "        for start_time in range(0, int(total_duration), chunk_size):\n",
    "            end_time = min(start_time + chunk_size, int(total_duration))\n",
    "            print(f\"Transcribing from {start_time:.2f} to {end_time:.2f} seconds...\")\n",
    "\n",
    "            # Extract the audio segment for transcription\n",
    "            chunk = audio_segment[start_time * 1000:end_time * 1000]  # Convert to milliseconds\n",
    "\n",
    "            # Convert the chunk to a byte stream in WAV format\n",
    "            wav_buffer = BytesIO()\n",
    "            chunk.export(wav_buffer, format=\"wav\")\n",
    "            wav_buffer.seek(0)\n",
    "\n",
    "            # Transcribe the audio chunk\n",
    "            with sr.AudioFile(wav_buffer) as source:\n",
    "                audio_data = recognizer.record(source)\n",
    "                try:\n",
    "                    text = recognizer.recognize_google(audio_data)\n",
    "                    transcribed_text.append(text)\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\"Google Speech Recognition could not understand the audio.\")\n",
    "                except sr.RequestError as e:\n",
    "                    print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "\n",
    "        # Combine the transcribed text\n",
    "        final_text = \" \".join(transcribed_text)\n",
    "\n",
    "        # Output the transcribed text\n",
    "        print(\"\\nThe resultant text from the video is:\\n\")\n",
    "        print(final_text)\n",
    "\n",
    "        # Save the transcription to a text file\n",
    "        with open(\"transcribed_text.txt\", \"w\") as file:\n",
    "            file.write(final_text)\n",
    "        print(\"\\nText saved to transcribed_text.txt\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "video_path = \"sample.mp4\"  # Replace with your video file path\n",
    "transcribe_video_to_text(video_path, chunk_size=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(audio_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: arrays to stack must be passed as a \"sequence\" type such as list or tuple.\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "# Function to transcribe video to text\n",
    "def transcribe_video_to_text(video_path, chunk_size=30):\n",
    "    try:\n",
    "        # Load the video file\n",
    "        video = mp.VideoFileClip(video_path)\n",
    "\n",
    "        # Check if the video has an audio track\n",
    "        if video.audio is None:\n",
    "            print(\"The video does not contain an audio track.\")\n",
    "            return\n",
    "\n",
    "        # Extract audio directly as numpy array\n",
    "        audio_array = video.audio.to_soundarray(fps=16000)\n",
    "\n",
    "        # Handle stereo to mono conversion if needed\n",
    "        if audio_array.ndim > 1:\n",
    "            audio_array = np.mean(audio_array, axis=1)  # Convert to mono\n",
    "\n",
    "        # Convert numpy array to bytes\n",
    "        audio_data = audio_array.tobytes()\n",
    "\n",
    "        # Create an AudioSegment from the byte data\n",
    "        audio_segment = AudioSegment(\n",
    "            audio_data,\n",
    "            frame_rate=16000,\n",
    "            sample_width=2,  # 2 bytes for int16\n",
    "            channels=1  # Mono\n",
    "        )\n",
    "\n",
    "        # Initialize recognizer\n",
    "        recognizer = sr.Recognizer()\n",
    "        total_duration = len(audio_segment) / 1000.0  # Duration in seconds\n",
    "        transcribed_text = []\n",
    "\n",
    "        # Process the audio in chunks\n",
    "        for start_time in range(0, int(total_duration), chunk_size):\n",
    "            end_time = min(start_time + chunk_size, int(total_duration))\n",
    "            print(f\"Transcribing from {start_time:.2f} to {end_time:.2f} seconds...\")\n",
    "\n",
    "            # Extract the audio segment for transcription\n",
    "            chunk = audio_segment[start_time * 1000:end_time * 1000]  # Convert to milliseconds\n",
    "\n",
    "            # Convert the chunk to a byte stream in WAV format\n",
    "            wav_buffer = BytesIO()\n",
    "            chunk.export(wav_buffer, format=\"wav\")\n",
    "            wav_buffer.seek(0)\n",
    "\n",
    "            # Transcribe the audio chunk\n",
    "            with sr.AudioFile(wav_buffer) as source:\n",
    "                audio_data = recognizer.record(source)\n",
    "                try:\n",
    "                    text = recognizer.recognize_google(audio_data)\n",
    "                    transcribed_text.append(text)\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\"Google Speech Recognition could not understand the audio.\")\n",
    "                except sr.RequestError as e:\n",
    "                    print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "\n",
    "        # Combine the transcribed text\n",
    "        final_text = \" \".join(transcribed_text)\n",
    "\n",
    "        # Output the transcribed text\n",
    "        print(\"\\nThe resultant text from the video is:\\n\")\n",
    "        print(final_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "video_path = \"a.mp4\"  # Replace with your video file path\n",
    "transcribe_video_to_text(video_path, chunk_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aftrai)",
   "language": "python",
   "name": "aftrai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
